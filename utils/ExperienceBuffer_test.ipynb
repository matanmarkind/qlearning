{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random, os, sys\n",
    "import numpy as np\n",
    "\n",
    "# Not a python script so can't use __file__ like elsewhere.\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(1, parent_dir)\n",
    "from utils.ExperienceBuffer import ExpBuf, WeightedExpBuf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hist(iterable, hasher = hash):\n",
    "    hist = defaultdict(int)\n",
    "    for i in iterable:\n",
    "        hist[hasher(i)] += 1\n",
    "    return dict(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['a', 'b', 'c', 'd']\n",
    "actions = [1, 2, 3, 4]\n",
    "rewards = [0, 1, 0, -1]\n",
    "next_states = ['b', 'c', 'd', 'e']\n",
    "is_terminals = [False, False, False, True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the plain experience buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 2, 1, 'c', True] : 313\n",
      "['c', 3, 0, 'd', True] : 261\n",
      "['d', 4, -1, 'e', False] : 326\n"
     ]
    }
   ],
   "source": [
    "ebuf = ExpBuf(3)  # keep small since lots of hand written stuff.\n",
    "for s, a, r, ns, it in zip(states, actions, rewards, next_states, is_terminals):\n",
    "    ebuf.append(s, a, r, ns, it)\n",
    "    \n",
    "eles = list()\n",
    "for i in range(900):\n",
    "    eles.append(ebuf.sample(1))\n",
    "    \n",
    "hist = make_hist(eles, lambda exp: str([e[0] for e in exp]))\n",
    "\n",
    "exp_keys = {\"['b', 2, 1, 'c', True]\",\n",
    "            \"['c', 3, 0, 'd', True]\",\n",
    "            \"['d', 4, -1, 'e', False]\"}\n",
    "assert set(hist.keys()) == exp_keys, \\\n",
    "    'Unexpected experiences in sample ' + str(hist.keys())\n",
    "\n",
    "for k, count in hist.items():\n",
    "    kv_str = k + \" : \" + str(count)\n",
    "    assert abs(count - 300) < 50, \"Non uniform sampling: \" + kv_str\n",
    "    print(kv_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Experience Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = .4\n",
    "b = .5\n",
    "b_f = 1\n",
    "b_anneal = 5\n",
    "e = .01\n",
    "wbuf = WeightedExpBuf(capacity=3, alpha=a, beta_i=b, beta_f=b_f,\n",
    "                      beta_anneal=b_anneal, weight_offset=e)\n",
    "for s, act, r, ns, term in zip(states, actions, rewards, next_states, is_terminals):\n",
    "    wbuf.append(s, act, r, ns, term)\n",
    "    \n",
    "raw_weights = np.array([0, .5, 3.4])  # b, c, d\n",
    "tot_weight = sum((raw_weights + e) ** a)\n",
    "wbuf.update_weights([1, 2, 3], raw_weights)  # indices wrap around for ring\n",
    "assert abs(tot_weight - wbuf.total_weight) < 1e-12,\\\n",
    "    'expected=' + str(tot_weight) + ' actual=' + str(wbuf.total_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use batch_size=1, since the way we sample, sample_n_subsets, breaks down the elements in the sum tree. We want this effect for actual sampling when experiences are commoditized (num_exp >> batch_size and weigh_exp << total_weight) but here that would throw off the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d': 637, 'c': 306, 'b': 57}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "n_samples = 1000\n",
    "assert n_samples % batch_size == 0,\\\n",
    "    \"Not a general requirement for wbuf\"\n",
    "\n",
    "index, state, action, reward, next_state, not_terminal, IS_weight = [], [], [], [], [], [], []\n",
    "for i in range(n_samples // batch_size):\n",
    "    ids, s, acts, r, ns, nt, IS = wbuf.sample(batch_size)\n",
    "    index += list(ids)\n",
    "    state += list(s)\n",
    "    action += list(acts)\n",
    "    reward += list(r)\n",
    "    next_state += list(ns)\n",
    "    IS_weight += list(IS)\n",
    "    \n",
    "hist = make_hist(state, lambda exp: exp)  # Use the state as hash\n",
    "\n",
    "assert set(hist.keys()) == {'b', 'c', 'd'}, str(hist.keys())\n",
    "\n",
    "expected = lambda weight: ((weight + e) ** a) / wbuf.total_weight\n",
    "\n",
    "assert abs(hist['b']/n_samples - expected(0)) < .1,\\\n",
    "    'count=' + str(hist['b']) + ' expected=' +\\\n",
    "    str(int(expected(0) * n_samples))\n",
    "assert abs(hist['c']/n_samples - expected(.5)) < .1,\\\n",
    "    'count=' + str(hist['c']) + ' expected=' +\\\n",
    "    str(int(expected(.5) * n_samples))\n",
    "assert abs(hist['d']/n_samples - expected(3.4)) < .1,\\\n",
    "    'count=' + str(hist['d']) + ' expected=' +\\\n",
    "    str(int(expected(3.4) * n_samples))\n",
    "\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 4 samples to get the 3 unique unexperiences transitions, and check that the 4th starts to repeat. Then inspect the values returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 1, 0, 1, 2]\n",
      "['d', 'b', 'c', 'b', 'd', 'b', 'c']\n",
      "[4, 2, 3, 2, 4, 2, 3]\n",
      "[-1, 1, 0, 1, -1, 1, 0]\n",
      "['e', 'c', 'd', 'c', 'e', 'c', 'd']\n",
      "[0.04700444715149313, 0.19054607179632474, 0.07416229446542934, 0.19054607179632474, 0.04700444715149313, 0.19054607179632474, 0.07416229446542934]\n"
     ]
    }
   ],
   "source": [
    "ids, s, acts, r, ns, nt, IS = wbuf.sample(3)\n",
    "index += list(ids)\n",
    "state += list(s)\n",
    "action += list(acts)\n",
    "reward += list(r)\n",
    "next_state += list(ns)\n",
    "IS_weight += list(IS)\n",
    "\n",
    "assert wbuf.sample(1)[1] in state\n",
    "    \n",
    "print(index)\n",
    "print(state)\n",
    "print(action)\n",
    "print(reward)\n",
    "print(next_state)\n",
    "print(IS_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use batch_size=2, and simply confirm that we see the smoothing effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d': 500, 'c': 424, 'b': 76}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "n_samples = 1000\n",
    "assert n_samples % batch_size == 0,\\\n",
    "    \"Not a general requirement for wbuf\"\n",
    "\n",
    "index, state, action, reward, next_state, not_terminal, IS_weight = [], [], [], [], [], [], []\n",
    "for i in range(n_samples // batch_size):\n",
    "    ids, s, acts, r, ns, nt, IS = wbuf.sample(batch_size)\n",
    "    index += list(ids)\n",
    "    state += list(s)\n",
    "    action += list(acts)\n",
    "    reward += list(r)\n",
    "    next_state += list(ns)\n",
    "    IS_weight += list(IS)\n",
    "    \n",
    "hist = make_hist(state, lambda exp: exp)  # Use the state as hash\n",
    "\n",
    "assert set(hist.keys()) == {'b', 'c', 'd'}, str(hist.keys())\n",
    "\n",
    "expected = lambda weight: ((weight + e) ** a) / wbuf.total_weight\n",
    "\n",
    "assert hist['b']/n_samples > expected(0),\\\n",
    "    'count=' + str(hist['b']) + ' expected=' +\\\n",
    "    str(int(expected(0) * n_samples))\n",
    "assert hist['c']/n_samples > expected(.5),\\\n",
    "    'count=' + str(hist['c']) + ' expected=' +\\\n",
    "    str(int(expected(.5) * n_samples))\n",
    "assert hist['d']/n_samples < expected(3.4),\\\n",
    "    'count=' + str(hist['d']) + ' expected=' +\\\n",
    "    str(int(expected(3.4) * n_samples))\n",
    "\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the weight of 'b' to be 1.3 and retest sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbuf.update_losses([1], [1.3]) # b's weight goes from 0 ==> 1.3\n",
    "net_weight += 1.3\n",
    "\n",
    "eles = list()\n",
    "for i in range(1000):\n",
    "    eles.append(wbuf.sample(1))\n",
    "hist = make_hist(eles, lambda exp: exp[1][0])  # Use the state as hash\n",
    "\n",
    "assert set(hist.keys()) == {'b', 'c', 'd'}, str(hist.keys())\n",
    "assert abs(hist['b']/1000 - 1.3/net_weight) < .1, \\\n",
    "    'Improper sampling: ' + str(hist)\n",
    "assert abs(hist['c']/1000 - .5/net_weight) < .1, \\\n",
    "    'Improper sampling: ' + str(hist)\n",
    "assert abs(hist['d']/1000 - 3.4/net_weight) < .1, \\\n",
    "    'Improper sampling: ' + str(hist)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
