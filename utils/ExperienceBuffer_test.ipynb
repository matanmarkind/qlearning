{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random, os, sys\n",
    "import numpy as np\n",
    "\n",
    "# Not a python script so can't use __file__ like elsewhere.\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(1, parent_dir)\n",
    "from utils.ExperienceBuffer import ExpBuf, WeightedExpBuf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hist(iterable, hasher = hash):\n",
    "    hist = defaultdict(int)\n",
    "    for i in iterable:\n",
    "        hist[hasher(i)] += 1\n",
    "    return dict(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['a', 'b', 'c', 'd']\n",
    "actions = [1, 2, 3, 4]\n",
    "rewards = [0, 1, 0, -1]\n",
    "next_states = ['b', 'c', 'd', 'e']\n",
    "is_terminals = [False, False, False, True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the plain experience buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 2, 1, 'c', True] : 307\n",
      "['d', 4, -1, 'e', False] : 290\n",
      "['c', 3, 0, 'd', True] : 303\n"
     ]
    }
   ],
   "source": [
    "ebuf = ExpBuf(3)  # keep small since lots of hand written stuff.\n",
    "for s, a, r, ns, it in zip(states, actions, rewards, next_states, is_terminals):\n",
    "    ebuf.append(s, a, r, ns, it)\n",
    "    \n",
    "eles = list()\n",
    "for i in range(900):\n",
    "    eles.append(ebuf.sample(1))\n",
    "    \n",
    "hist = make_hist(eles, lambda exp: str([e[0] for e in exp]))\n",
    "\n",
    "exp_keys = {\"['b', 2, 1, 'c', True]\",\n",
    "            \"['c', 3, 0, 'd', True]\",\n",
    "            \"['d', 4, -1, 'e', False]\"}\n",
    "assert set(hist.keys()) == exp_keys, \\\n",
    "    'Unexpected experiences in sample ' + str(hist.keys())\n",
    "\n",
    "for k, count in hist.items():\n",
    "    kv_str = k + \" : \" + str(count)\n",
    "    assert abs(count - 300) < 50, \"Non uniform sampling: \" + kv_str\n",
    "    print(kv_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Experience Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = .4\n",
    "b = .5\n",
    "b_f = 1\n",
    "b_anneal = 5\n",
    "e = .01\n",
    "wbuf = WeightedExpBuf(capacity=3, alpha=a, beta_i=b, beta_f=b_f,\n",
    "                      beta_anneal=b_anneal, weight_offset=e)\n",
    "effective_weight = lambda raw_weight: (raw_weight + e) ** a\n",
    "P_select = lambda raw_weight: effective_weight(raw_weight) / wbuf.total_weight\n",
    "\n",
    "for s, act, r, ns, term in zip(states, actions, rewards, next_states, is_terminals):\n",
    "    wbuf.append(s, act, r, ns, term)\n",
    "    \n",
    "raw_weights = np.array([0, .5, 3.4])  # b, c, d\n",
    "tot_weight = sum(effective_weight(raw_weights))\n",
    "wbuf.update_weights([1, 2, 3], raw_weights)  # indices wrap around for ring\n",
    "assert abs(tot_weight - wbuf.total_weight) < 1e-12,\\\n",
    "    'expected=' + str(tot_weight) + ' actual=' + str(wbuf.total_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 3 samples should be 1 from each experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, state, action, reward, next_state, not_terminal, IS_weight = [], [], [], [], [], [], []\n",
    "ids, s, acts, r, ns, nt, IS = wbuf.sample(3)\n",
    "index += list(ids)\n",
    "state += list(s)\n",
    "action += list(acts)\n",
    "reward += list(r)\n",
    "next_state += list(ns)\n",
    "not_terminal += list(nt)\n",
    "IS_weight += list(IS)\n",
    "\n",
    "assert set(ids) == {0, 1, 2}, ids\n",
    "assert set(state) == {'b', 'c', 'd'}, state\n",
    "assert set(action) == {2, 3, 4}, action\n",
    "assert set(reward) == {1, 0, -1}, reward\n",
    "assert set(next_state) == {'c', 'd', 'e'}, next_state\n",
    "assert set(not_terminal) == {True, True, False}, not_terminal\n",
    "assert set(IS_weight) == {1, 1, 1},\\\n",
    "    'weights should be 1 for first sampling: actual=' + str(IS_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use batch_size=1, since the way we sample, sample_n_subsets, breaks down the elements in the sum tree. We want this effect for actual sampling when experiences are commoditized (num_exp >> batch_size and weigh_exp << total_weight) but here that would throw off the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "n_samples = 1000\n",
    "assert n_samples % batch_size == 0,\\\n",
    "    \"Not a general requirement for wbuf\"\n",
    "\n",
    "def check_count(hist, key, raw_weight):\n",
    "    exp_rate = P_select(raw_weight)\n",
    "    assert abs(hist[key] / n_samples - exp_rate) < .1,\\\n",
    "        'count=' + str(hist[key]) + ' expected=' +\\\n",
    "        str(int(exp_rate * n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': 281, 'd': 666, 'b': 53}\n"
     ]
    }
   ],
   "source": [
    "index, state, action, reward, next_state, not_terminal, IS_weight = [], [], [], [], [], [], []\n",
    "for i in range(n_samples // batch_size):\n",
    "    ids, s, acts, r, ns, nt, IS = wbuf.sample(batch_size)\n",
    "    index += list(ids)\n",
    "    state += list(s)\n",
    "    action += list(acts)\n",
    "    reward += list(r)\n",
    "    next_state += list(ns)\n",
    "    IS_weight += list(IS)\n",
    "    \n",
    "hist = make_hist(state, lambda exp: exp)  # Use the state as hash\n",
    "print(hist)\n",
    "\n",
    "assert set(hist.keys()) == {'b', 'c', 'd'}, str(hist.keys())\n",
    "\n",
    "check_count(hist, 'b', 0)\n",
    "check_count(hist, 'c', .5)\n",
    "check_count(hist, 'd', 3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_rates = P_select(raw_weights)\n",
    "raw_IS_weights = ((wbuf.capacity * selection_rates) ** -wbuf.beta)\n",
    "exp_IS_weights = set(raw_IS_weights / max(raw_IS_weights))\n",
    "\n",
    "assert set(IS_weight) == exp_IS_weights,\\\n",
    "    'expected=' + str(exp_IS_weights) +\\\n",
    "    ' actual=' + str(set(IS_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use batch_size=2, and simply confirm that we see the smoothing effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': 420, 'd': 500, 'b': 80}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "n_samples = 1000\n",
    "assert n_samples % batch_size == 0,\\\n",
    "    \"Not a general requirement for wbuf\"\n",
    "\n",
    "index, state, action, reward, next_state, not_terminal, IS_weight = [], [], [], [], [], [], []\n",
    "for i in range(n_samples // batch_size):\n",
    "    ids, s, acts, r, ns, nt, IS = wbuf.sample(batch_size)\n",
    "    index += list(ids)\n",
    "    state += list(s)\n",
    "    action += list(acts)\n",
    "    reward += list(r)\n",
    "    next_state += list(ns)\n",
    "    IS_weight += list(IS)\n",
    "    \n",
    "hist = make_hist(state, lambda exp: exp)  # Use the state as hash\n",
    "print(hist)\n",
    "\n",
    "assert set(hist.keys()) == {'b', 'c', 'd'}, str(hist.keys())\n",
    "\n",
    "expected = lambda weight: ((weight + e) ** a) / wbuf.total_weight\n",
    "\n",
    "assert hist['b']/n_samples > expected(0),\\\n",
    "    'count=' + str(hist['b']) + ' expected=' +\\\n",
    "    str(int(expected(0) * n_samples))\n",
    "assert hist['c']/n_samples > expected(.5),\\\n",
    "    'count=' + str(hist['c']) + ' expected=' +\\\n",
    "    str(int(expected(.5) * n_samples))\n",
    "assert hist['d']/n_samples < expected(3.4),\\\n",
    "    'count=' + str(hist['d']) + ' expected=' +\\\n",
    "    str(int(expected(3.4) * n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the weight of 'b' to be 1.3 and retest sampling. Now that 'd' doesn't dominate as much check that the sample_n_subset is spread out nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 314, 'd': 457, 'c': 229}\n"
     ]
    }
   ],
   "source": [
    "wbuf.update_weights(np.array([1]), np.array([1.3])) # b's weight goes from 0 ==> 1.3\n",
    "\n",
    "eles = list()\n",
    "for i in range(1000):\n",
    "    eles.append(wbuf.sample(1))\n",
    "hist = make_hist(eles, lambda exp: exp[1][0])  # Use the state as hash\n",
    "print(hist)\n",
    "\n",
    "assert set(hist.keys()) == {'b', 'c', 'd'}, str(hist.keys())\n",
    "\n",
    "assert abs(hist['b']/n_samples - P_select(1.3)) < .1,\\\n",
    "    'count=' + str(hist['b']) + ' expected=' +\\\n",
    "    str(int(expected(1.3) * n_samples))\n",
    "assert abs(hist['c']/n_samples - P_select(.5)) < .1,\\\n",
    "    'count=' + str(hist['b']) + ' expected=' +\\\n",
    "    str(int(expected(.5) * n_samples))\n",
    "assert abs(hist['d']/n_samples - P_select(3.4)) < .1,\\\n",
    "    'count=' + str(hist['b']) + ' expected=' +\\\n",
    "    str(int(expected(3.4) * n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update weights a whole bunch and check that the beta stays at the final value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    wbuf.update_weights([1], np.array([1.3]))\n",
    "assert abs(b_f - wbuf.beta_f) < 1e-12,\\\n",
    "    'expected=' + str(b_f) + ' actual=' + str(wbuf.beta_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
